{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-Net from Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN7qfHWolCmkD4IleAeiCnW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ankan1998/paper-implementation/blob/main/U_Net_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcFnNIIS5O7W"
      },
      "source": [
        "## U-Net Architecture paper implementation from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moa9wcj75kr1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkQdTt-A5HZx"
      },
      "source": [
        "def double_down_conv(in_c,out_c):\n",
        "    d_conv_seq=nn.Sequential(\n",
        "          nn.Conv2d(in_c,out_c,kernel_size=3),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Conv2d(out_c,out_c,kernel_size=3),\n",
        "          nn.ReLU(inplace=True)\n",
        "        )\n",
        "    return d_conv_seq\n",
        "\n",
        "def crop_tensor(target,original):\n",
        "\n",
        "  target_size=target.size()[2]\n",
        "  original_size=original.size()[2]\n",
        "  diff=original_size-target_size\n",
        "  diff=diff//2\n",
        "  return original[:,:,diff:original_size-diff,diff:original_size-diff]\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    # Layers \n",
        "    # 1st part\n",
        "    self.mpool2d=nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    self.dconv1=double_down_conv(1,64)\n",
        "    self.dconv2=double_down_conv(64,128)\n",
        "    self.dconv3=double_down_conv(128,256)\n",
        "    self.dconv4=double_down_conv(256,512)\n",
        "    self.dconv5=double_down_conv(512,1024)\n",
        "\n",
        "\n",
        "    # 2nd part\n",
        "    self.tconv1=nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2)\n",
        "    self.tconv2=nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
        "    self.tconv3=nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n",
        "    self.tconv4=nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n",
        "\n",
        "    self.double_u_conv1=double_down_conv(1024,512)\n",
        "    self.double_u_conv2=double_down_conv(512,256)\n",
        "    self.double_u_conv3=double_down_conv(256,128)\n",
        "    self.double_u_conv4=double_down_conv(128,64)\n",
        "\n",
        "\n",
        "    self.out=nn.Conv2d(64,2,kernel_size=1)\n",
        "    \n",
        "\n",
        "  def forward(self,image):\n",
        "\n",
        "    # Encoder part\n",
        "    x1=self.dconv1(image) #\n",
        "    x2=self.mpool2d(x1)\n",
        "    x3=self.dconv2(x2) #\n",
        "    x4=self.mpool2d(x3)\n",
        "    x5=self.dconv3(x4) #\n",
        "    x6=self.mpool2d(x5)\n",
        "    x8=self.dconv4(x6) #\n",
        "    x9=self.mpool2d(x8)\n",
        "    x10=self.dconv5(x9)\n",
        "\n",
        "    # Decoder Part\n",
        "\n",
        "    x11=self.tconv1(x10)\n",
        "    xnew1=crop_tensor(x11,x8)\n",
        "    x12=self.double_u_conv1(torch.cat([x11,xnew1],1))\n",
        "\n",
        "\n",
        "    x13=self.tconv2(x12)\n",
        "    xnew2=crop_tensor(x13,x5)\n",
        "    x14=self.double_u_conv2(torch.cat([x13,xnew2],1))\n",
        "\n",
        "\n",
        "    x15=self.tconv3(x14)\n",
        "    xnew3=crop_tensor(x15,x3)\n",
        "    x16=self.double_u_conv3(torch.cat([x15,xnew3],1))\n",
        "\n",
        "\n",
        "    x17=self.tconv4(x16)\n",
        "    xnew4=crop_tensor(x17,x1)\n",
        "    x18=self.double_u_conv4(torch.cat([x17,xnew4],1))\n",
        "\n",
        "    print(\"x18\",x18.size())\n",
        "    xfinal=self.out(x18)\n",
        "    print(\"xfinal\",xfinal.size())\n",
        "\n",
        "    return xfinal\n",
        "    \n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGhafZSRzT36"
      },
      "source": [
        "model=UNet()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRWL0B3Qzbkm",
        "outputId": "74fc83f4-7411-4e26-88e3-95f2828904f7"
      },
      "source": [
        "image=torch.rand((1,1,572,572))\n",
        "model(image)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x18 torch.Size([1, 64, 388, 388])\n",
            "xfinal torch.Size([1, 2, 388, 388])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.0810,  0.0788,  0.0853,  ...,  0.0762,  0.0843,  0.0795],\n",
              "          [ 0.0862,  0.0845,  0.0850,  ...,  0.0782,  0.0839,  0.0836],\n",
              "          [ 0.0859,  0.0769,  0.0758,  ...,  0.0855,  0.0804,  0.0826],\n",
              "          ...,\n",
              "          [ 0.0854,  0.0831,  0.0811,  ...,  0.0861,  0.0842,  0.0798],\n",
              "          [ 0.0830,  0.0819,  0.0849,  ...,  0.0812,  0.0814,  0.0838],\n",
              "          [ 0.0852,  0.0912,  0.0848,  ...,  0.0832,  0.0822,  0.0800]],\n",
              "\n",
              "         [[-0.0956, -0.0923, -0.1020,  ..., -0.0932, -0.0985, -0.0962],\n",
              "          [-0.1000, -0.0979, -0.0969,  ..., -0.0941, -0.0987, -0.0977],\n",
              "          [-0.0983, -0.1003, -0.0958,  ..., -0.0958, -0.0903, -0.0984],\n",
              "          ...,\n",
              "          [-0.1000, -0.0981, -0.0942,  ..., -0.0974, -0.0957, -0.0994],\n",
              "          [-0.0928, -0.1027, -0.0986,  ..., -0.0985, -0.0995, -0.0910],\n",
              "          [-0.0948, -0.0948, -0.0979,  ..., -0.0923, -0.1052, -0.0935]]]],\n",
              "       grad_fn=<MkldnnConvolutionBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}